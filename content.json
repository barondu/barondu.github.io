[{"title":"","date":"2019-07-01T21:51:20.742Z","path":"2019/07/01/Deadlocks/","text":"—————title: OSC_Deadlocksdate: 2017-04-03 23:10:14categories: - 笔记 tags: - G52OSC - Deadlocks Deadlocks Overview Deadlocks and conditions for deadlocks Algorithms to detect[探知] deadlocksApproaches to recover from deadlocks DeadlocksHow Occur deadlocks?[看看就好] Some resources are mutually exclusive and can only be used by one process at a time On occasions[偶然], multiple processes will require access to multiple mutually exclusive resources (e.g. process A and B need resources X and Y) Process A and B request the resources in opposite orders and end up in deadlock Deadlocks can occur on the same machine or between multiple machines (e.g. resources are requested over the network) and any number of resources Deadlocks are not just related to operating systems but also occur, e.g., in databases resource A resource (e.g. a device, a data record, file, semaphore) can be acquired, used, and released A resource can be preemptable, i.e., it can be forcefully taken away from the process without permanent adverse effect A resource can be non-preemptable, i.e., it cannot be taken away from a process without permanent adverse effect If a non-preemptable resource is requested but not available, the process is made to wait Deadlocks only occur for non-preemtable resources because preemtable resources can be temporarily taken away to recover from the deadlock Definition “A set of processes is deadlocked if each process in the set is waiting for an event that only the other process in the set can cause” – Tanenbaum Each deadlocked process is waiting for a resource held by an other deadlocked process (which cannot run and hence cannot release the resources) This can happen between any number of processes and for any number of resources ConditionsFour conditions must hold for deadlocks to occur (Coffman et al. (1971)): Mutual exclusion: a resource can be assigned to at most one process at a time Hold and wait condition: a resource can be held whilst[同时] requesting new resources No preemption: resources cannot be forcefully taken away from a process Circular wait: there is a circular chain of two or more processes, waiting for a resource held by the other processes No deadlocks can occur if one of the conditions is not satisfied","tags":[]},{"title":"G52CPP复习","date":"2018-11-26T03:27:27.000Z","path":"2018/11/26/G52CPP/","text":"G52CPP Lecture 1 &amp; 2Header12#include &lt;stdio.h&gt; // C or C++#include &lt;cstdio&gt; // C++ reference 省去 copy的过程What is usually in a header file? Function declarations Macro definitions (#define) Constant definitions Possibly other things as well Ensure that the header file #includes everything that it needs itself Ensure that it doesn’t matter if the header file is #included multiple times Ensure that header files can be included in any order #includeReplaces this statement by the text of the specified file Java’s import Sizes of types A minimum size (bits): char 8(1 byte), short 16(2 byte), long 32(4 byte) Relativesizes: char &lt;= short &lt;= int &lt;= long bool and inttype bool : true / false (C++ only, not C) IMPORTANT: bool and int can be converted implicitly / automatically to each other true defined to be 1 when converted to int false defined to be 0 when converted to int 0 is defined to be false, non-zero as true In both C and C++ any integer types can be used in conditions (i.e. char, short, long, int)123456int x = 6;while ( x )&#123; printf( \"X is %d\\n\", x ); x -= 2; &#125; 123456789101112131415161718192021222324##### wchar_t typewchar_t : wide character (C++ only, not C)- 16 bits##### signed/unsigned value- Default is **signed**##### void- you can create a type void##### auto- new to C++11- can only used for **initialised variables** - complier will **work out the type** at **compile time** from **the initialisation value**##### #define&gt; An semi-intelligent ***‘find and replace**’* facility- Often considered `bad` in C++ code (useful in C) - **const** is used more often, especially for members - **Template functions** are better than **macros**- **Remember**: Done by the pre-processor!- Constant `#define` usually written in **CAPITALS**##### Conditional compilationYou can remove parts of the source code if desired- Use for **cross-platform** code #ifdef WINDOWS… windows code here … #elif SYS5UNIX… System 5 code here … #endif1- Avoiding multiple inclusion #ifndef UNIQUE_DEFINE_NAME_FOR_FILE #define UNIQUE_DEFINE_NAME_FOR_FILE… include the rest of the file here … #endif123456789101112131415别忘了endif### Lecture 3 &amp; 4##### Pointer![Alt text](./1496502642897.png)- `&amp;` Address-of- `*` De-referencingIn C and C++, variables are **NOT initialised** unless you give them an **initial value**- You can use NULL- **Dereferencing an unitialised pointer** has undefined results *Could crash your program (likely)*- assigning one pointer to another means: - It points at the same object - It has the same address stored in it ##### Casting char c1 = ‘h’;char pc2 = &c1;int pi4 = (int*)pc2;12- **Dangerous !**print the address use `%p` and `(void*)` char c1 = ‘h’;char pc2 = &c1;printf(“%p “,(void)pc2);printf(“%p\\n”,(void*)&amp;c1);123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687##### Arrays, C-strings and pointersArray- `char array[6];`- `char array[2] = &#123;'a','b'&#125;`- `char array[] = &#123;'a','b'&#125;`- The addresses of elements **within** an array **are** consecutive- The relative locations of **different array**s, or **variables are NOT** fixedC-string / char*- C-strings consist of an array of characters, terminated by a character value of zero- ‘\\0’, or 0 - NOT ‘0’!!! &gt; char* str = \"abcd\";&gt; str 是 ‘h’ 也就是第一个、字符的地址&gt; char array[4] = &#123;'a','b','c','d','/0'&#125;;&gt; char array[4] = \"abcd\";&gt; array 就是 'h', 就是第一个字符- char* 是只读的![12689f76eab6d982f416cc4f6e15e466.png](evernotecid://A4C2A14E-E2AB-40E7-9264-1D440DF81A61/appyinxiangcom/14488959/ENNote/p60?hash=12689f76eab6d982f416cc4f6e15e466)这里两个print出来的都是整个string### Lecture 5![6a4ee268a72a8b9dc7c7b83f68cba2e4.png](evernotecid://A4C2A14E-E2AB-40E7-9264-1D440DF81A61/appyinxiangcom/14488959/ENNote/p60?hash=6a4ee268a72a8b9dc7c7b83f68cba2e4)##### stack- last in fist out (LIFO)- Function calls (stack frames) are stored on a stack in memory- stack frame![52a56050e9f28bc036a1906cfd328d0d.png](evernotecid://A4C2A14E-E2AB-40E7-9264-1D440DF81A61/appyinxiangcom/14488959/ENNote/p60?hash=52a56050e9f28bc036a1906cfd328d0d)##### Lifetime of local variables- Your local variables only exist for as long as the block in which they are defined- Do not access them after that- Do not assume that they keep their value after the function ends- Local variables get destroyed for you (auto-destroyed)- But if you use malloc() you need to call free()##### Global variables- Variable declared outside of all functions- Global variables last for the duration of the program- All functions in the file can access globals- Not available in Java!##### Static local variablesLocal variables can be **static**- Means not moving/unchanging- NOT the same as static member variables!- NOT the same as **const**Static local variables remember their value between function calls- Like global variablesBut, you can only access them (by name) inside the one function they are defined in- Unless you keep a pointer to themStatic variable remembers its value Initialisation only occurs in the first function call##### Global vs local variables![552b5511aef4638112f5f5a7fb995764.png](evernotecid://A4C2A14E-E2AB-40E7-9264-1D440DF81A61/appyinxiangcom/14488959/ENNote/p60?hash=552b5511aef4638112f5f5a7fb995764)Do not refer to data on the stack outside the function- This means local variables or actual parametersYou CAN refer to them, but SHOULD NOT&gt;Things to avoid:&gt; - Returning a pointer to a local variable or parameter &gt; - Storing the address of a local variable or parameter##### Using multiple files![05f1607f86a43382e00ef97a21735133.png](evernotecid://A4C2A14E-E2AB-40E7-9264-1D440DF81A61/appyinxiangcom/14488959/ENNote/p60?hash=05f1607f86a43382e00ef97a21735133)- `extern`![d926279ef50ca572eaf0f5e80ee74d23.png](evernotecid://A4C2A14E-E2AB-40E7-9264-1D440DF81A61/appyinxiangcom/14488959/ENNote/p60?hash=d926279ef50ca572eaf0f5e80ee74d23)##### Encapsulation![a0e03a14297eb01f82df1eb75191bae6.png](evernotecid://A4C2A14E-E2AB-40E7-9264-1D440DF81A61/appyinxiangcom/14488959/ENNote/p60?hash=a0e03a14297eb01f82df1eb75191bae6)### Lecture 6##### struct``` struct Time&#123; int hour; int minuate; int second;&#125;;struct Date &#123; int d, m, y; &#125;; 1struct Date dob = &#123; 1, 4, 1990 &#125;; 注意分号！Use . to access struct members The heap and malloc() malloc() returns a void* 1int* pInt = (int*)malloc( sizeof(int) ) Positioning of struct elements #pragma struct may get empty space in them To align members for maximum speed -#pragma means a compiler/operating system specific pre-processor directive - `#pragma pack(1)` it will save space but will speed down union Elements of unions are in the SAME place Elements of unions may be different sizes A union is as big as the biggest thing in it Unions are a way of providing different ways of looking at the same memory Lecture 7classes vs structs in C++ Everything you do with a class in C++ could also be done with a struct The difference is (ONLY!!!) in encapsulation struct defaults to public, class to private struct: Data only and no member functions Data should (usually) be private Methods (functions) should be: private for internal use only public for the external class interface The values of the data members comprise the state of the object Interface methods can be: Mutators – change the ‘state’ of the object Accessors – only query values, no changes Use this-&gt;notthis. Constructors and DestructorsConstructor (as in Java) Called when an object is created Has function name same as class name no return type (none/empty, NOT void!) Adding a constructor makes it impossible to provide a C-style initialiser. e.g. = {0,1,2}; Destructor (similar to Java finalize) Called when an object is destroyed A function with name ~ then class name • E.g.: ~DemoClass() And no return type Default parameters Default values appear only in the function declaration, not any separate definition Use `= ‘’12DemoClass( char* dummy, int iValue = -1)&#123; /*Nothing*/ &#125; Default ConstructorThe ‘Default Constructor’ is a constructor which can be called with no parameters e.g. one which has no parameters or has default values for all parameters A class can only have one default constructor More would introduce ambiguity When you create arrays of objects, the default constructor is used (because no parameters are provided):DemoClass myDemoArray[4]; IMPORTANT: Do NOT add empty brackets () when constructing on the stack if there are no parameters! Compiler thinks you are declaring a function e.g. DemoClass myDemoClass1(); // WRONG!!! Initialisation vs AssignmentCompare the following:1)1int i = 4; // Initialisation 2)12int j; // Uninitialisedj = 4; // Assignment Member data is NOT always initialised Basic types and pointers (e.g. int, short or char*) are NOT initialised Default constructor is called for members of type class/struct unless you say otherwise Using initialisation list Inline functionsUse the keyword inline, e.g.:1inline int max( int a, int b ) &#123; return a&gt;b ? a : b; &#125; Similar to a ‘safe’ macro expansion Safely replaces the function call with the code Unlike a macro (#define) Avoids the overhead of creating a stack frame Code gets included in EVERY file/function which calls it VERY useful for small, fast functions Defining functions within the class declaration implicitly makes them inline Function set default value for parameters in declaration. Lecture8ReferenceA way to give a new name to an item12int i = 1;int&amp; j = i; References always have to refer to something Must give them a thing to refer to on initialisation No such thing as a NULL reference do NOT return a reference to a local variable The need for references Useful if we need to keep the same syntax Useful as return values, to chain functions together References are necessary for operator overloading Passing parameters When a function is called, the values of the parameters are copied into the stack frame for the new function New and Delete1234MyClass* pOb = new MyClass;delete pOb;MyClass* pObArray = new MyClass[4];delete [] pObArray; delete destroys an object It cares about the object type Calls the destructor of the class it thinks the thing is (using pointer type) and then frees the memory You MUST delete anything which you createusing new You MUST delete [] ... any arrays which you create using new ... [] You MUST free any memory which youmalloc/alloc/calloc/realloc If you want to create objects in dynamic memory then you must go through newYou can use new on basic types (e.g.int)Array new [] uses the default constructor for objects, and does not initialise basic types Lecture 9this and staticStatic member functions do not have a this pointer const Pointers to constant data12const char * p=“Hello”; char const * p=“Hello”; Constant pointers 1char* const p = “Hello”; String literalString literals should not be changed1const char* str = “Hello”; const references const references make the thing referred to const const references are useful for parameters Passing by value (not reference) means the original variable (safer)cannot be accidentally modified Passing a reference means that no copy is made (maybe quicker) Using a const reference means no copy needs to be made, but the original can still not be changed, like a copy but faster mutable 提前 奶一口 const 就能改了 friend friend 写在 被用的那个class里，就可以访问private的了 Lecture 10NamespaceNamespaces are used to avoid name conflicts Only the name is affectednamespace &lt;NamespaceName&gt;{} 123456&lt;namespace&gt;::&lt;class&gt;::&lt;function&gt;MyNameSpace::MyClass::foo();&lt;namespace&gt;::&lt;globalfunction&gt; MyNameSpace::bar();using namespace &lt;namespace&gt; scoping::Left of scoping operator is blank (to access a global variable/function) class name (to access member of that class) namespace name (to use that namespace) streams for input/output File access using streams ifstream object - open the file for input ofstream object - open the file for output fstream object – specify what to open file for stringstream Lecture 11 没有virtual的时候pSubAsBase-&gt;foo()是调用父类的如果父类方法 virtual之后，再这么访问，要看pSubAsBase到底是什么class vitual 之后想用父类的function 就要 用到 :: 1 2 34 5 6 Inheritance and constructorscreate in stack create in heap Do not call virtual functions from the constructor or destructor 想要也删掉sub的，把父类的destructor加virtual Lecture 13Function pointers Function pointers 括号里是paraeter callback function Virtual and non-virtual functions Lecture 144 functions created by default if needed You can make them unavailable (e.g. private) A defaul tconstructor(no parameters needed) A copy constructor (copy one object to another) An assignment operator (=operator) A destructor A default constructor Automatically created if and only if you do NOT create any other constructors The Copy Constructor The copy constructor is used to initialise one object from another of the same type 12MyClass( const MyClass&amp; rhs )&#123;...&#125; Takes a constant reference to the object to copy from Has to be a reference! Assignment operator Used when value of one object is assigned to another ob1=ob2=ob3=ob4; Destructor Default destructor does nothing Conversion constructor A conversion constructor is a constructor with one parameter.123MyClass( char c )&#123; ... do something with c ... &#125;MyClass ob = ‘h’; int 就可以这么用 conversion operator explictProviding a one-parameter constructor provides a conversion constructor Lecture 15Casting static cast dynamic cast const cast reinterpret cast casting-ness是强转比如int&amp; xr = (int&amp;)(x);，尽量避免 dynamic 失败的时候会抛出exception 所以，sub base class转的时候。用dynamic.Pointer:12345BouncingBall game;BaseEngine* pGame = &amp;game; // No castBouncingBall* pmGame = dynamic_cast&lt;BouncingBall*&gt;(pGame);if ( pGame==NULL ) &#123; /* Failed */ &#125; Reference:123456789101112BouncingBall game;BaseGameEngine&amp; rgame = game; // No casttry&#123;BouncingBall&amp; rmgame = dynamic_cast&lt;BouncingBall&amp;&gt;(rgame);&#125;catch ( std::bad_cast b )&#123;// Handle the exception// Happens if rgame is NOT a BouncingBall&#125; Operator overloadingnon-mumber function别忘了friend123MyFloat operator-( const MyFloat&amp; lhs, const MyFloat&amp; rhs ) &#123;MyFloat temp(lhs.strName + \"-\" + rhs.strName, lhs.f - rhs.f);return temp; mumber function Operator overloading restrictions Lecture 16= and != + and += template123template &lt; typename T &gt;T mymax( T a, T b )&#123; return a &gt; b ? a : b; &#125; The compiler will actually generate the functions which are needed, according to the parameters Lecture 17FunctorFunctors are classes which overload the () operator Lecture 18How do we report errors? Return an error value from function Set a global error code Throw an exception (to report error) catch catch clauses are checked in the order in which they are encountered Exceptions are thrown by value Catch by reference or by value would work - Catch by reference avoids the copy catch ( ... ) will match ANY exceptioncatch ( BaseClass&amp; b ) { }will also catch sub-class objectscatch ( BaseClass* b ) { }will also catch sub-class pointers LambdaLambdas are anonymous functors that get created on the fly Basic lambda function:12[Capture] ( parameters ) -&gt; return_type &#123; function body &#125;[iAdd]( int i )-&gt;int &#123; return i + iAdd; &#125;","tags":[{"name":"CPP","slug":"CPP","permalink":"http://www.barondu.com/tags/CPP/"},{"name":"C++","slug":"C","permalink":"http://www.barondu.com/tags/C/"}]},{"title":"PyCharm运行TensorBoard时的小BUG","date":"2018-02-21T16:03:41.000Z","path":"2018/02/21/PyCharm运行TensorBoard时的小BUG/","text":"PyCharm运行TensorBoard时的小BUG@(G53IDS)[PyCharm, TensorBoard, BUG]今天在PyCharm的Terminal使用TensorBoard的时候出现了以下报错，但是mac自带的terminal却可以正常使用： 12345678910111213# tensorboard --logdir=logsTraceback (most recent call last): File \"/Users/baron/.pyenv/versions/3.6.3/bin/tensorboard\", line 11, in &lt;module&gt; sys.exit(main()) File \"/Users/baron/.pyenv/versions/3.6.3/lib/python3.6/site-packages/tensorboard/main.py\", line 45, in main default.get_assets_zip_provider()) File \"/Users/baron/.pyenv/versions/3.6.3/lib/python3.6/site-packages/tensorboard/program.py\", line 147, in main util.setup_logging() File \"/Users/baron/.pyenv/versions/3.6.3/lib/python3.6/site-packages/tensorboard/util.py\", line 50, in setup_logging locale.setlocale(locale.LC_ALL, '') File \"/Users/baron/.pyenv/versions/3.6.3/lib/python3.6/locale.py\", line 598, in setlocale return _setlocale(category, locale)locale.Error: unsupported locale setting 输入locale查看下是什么状况 123456789# localeLANG=LC_COLLATE=\"C\"LC_CTYPE=\"C\"LC_MESSAGES=\"C\"LC_MONETARY=\"C\"LC_NUMERIC=\"C\"LC_TIME=\"C\"LC_ALL= 发现原来是语言设置除了问题，LC_ALL后面什么都没有，于是我们的解决办法就是 1export LC_ALL=\"C\" 然后世界就和平了(｡･ω･｡)ﾉ","tags":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://www.barondu.com/tags/Machine-Learning/"},{"name":"TensorFlow","slug":"TensorFlow","permalink":"http://www.barondu.com/tags/TensorFlow/"},{"name":"pyenv","slug":"pyenv","permalink":"http://www.barondu.com/tags/pyenv/"},{"name":"PyCharm","slug":"PyCharm","permalink":"http://www.barondu.com/tags/PyCharm/"}]},{"title":"Hexo以及yilia主题个性化设置","date":"2017-11-26T03:11:27.000Z","path":"2017/11/26/Hexo以及yilia主题个性化设置/","text":"Hexo以及yilia主题个性化设置修改浏览器Tab里的icon修改后效果如下 很简单我们只需要在yilia主题里_config.yml文件里修改为favicon: /img/favicon.ico 将自己想要的icon，转换成.ico格式修改命名放在yilia/sourse/img里，大功告成 添加评论模块评论系统真的是折腾死我了，国内第三方免费平台接连停止服务 都有那些常用的评论系统 最开始用的多说，省心免费虽然总是挂掉，今年7月份就停止服务了 网易云跟帖也宣布即将停止服务。Gitment是一款一款基于GitHub Issues 的评论系统，所以只能用GitHub帐号登录 Disqus则已经被墙 目前可选择的评论系统还有友言，畅言，来必力等 畅言最蛋疼的是需要你的域名已经在国内备案过（内心飘过一万只草泥马 如何添加来必力评论系统我最终选择了来必力，虽然它总公司是韩国的，但是看在免费且支持的第三方登录的种类的面子上，就选它了。 注册帐户，登录选择个人网站安装city免费版就好，复制它给你的安装代码 123456789101112131415161718&lt;!-- 来必力City版安装代码 --&gt;&lt;div id=\"lv-container\" data-id=\"city\" data-uid=\"切记这里改成你账户里自己的ID\"&gt;&lt;script type=\"text/javascript\"&gt; (function(d, s) &#123; var j, e = d.getElementsByTagName(s)[0]; if (typeof LivereTower === 'function') &#123; return; &#125; j = d.createElement(s); j.src = 'https://cdn-city.livere.com/js/embed.dist.js'; j.async = true; e.parentNode.insertBefore(j, e); &#125;)(document, 'script');&lt;/script&gt;&lt;noscript&gt;为正常使用来必力评论功能请激活JavaScript&lt;/noscript&gt;&lt;/div&gt;&lt;!-- City版安装代码已完成 --&gt; 在themes\\yilia\\layout\\_partial\\post 目录下新建一个livere.ejs文件，粘贴之前的安装代码然后save 在themes\\yilia\\_config.yml里duoshuo: false前添加livere: true注意顺序 themes\\yilia\\layout\\_partial\\article.ejs中&lt;% if (!index &amp;&amp; post.comments){ %&gt;这行代码下面添加 1234567&lt;% if (theme.livere)&#123; %&gt;&lt;%- partial('post/livere', &#123; key: post.slug, title: post.title, url: config.url+url_for(post.path) &#125;) %&gt;&lt;% &#125; %&gt; Done！","tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://www.barondu.com/tags/Hexo/"},{"name":"yilia","slug":"yilia","permalink":"http://www.barondu.com/tags/yilia/"},{"name":"blog","slug":"blog","permalink":"http://www.barondu.com/tags/blog/"}]},{"title":"Installing TensorFlow","date":"2017-11-17T19:43:51.000Z","path":"2017/11/17/TensorFlow/","text":"TensorFlow配置环境我的环境是 macOS Sierra 10.12.6，其他mac版本应该也适用。 pyenv安装pyenv 管理多版本 python，通过它安装 python。原因是不希望污染mac自带系统python。详细过程参考官方doc，这里描述一下我的安装过程。 安装： 12345# 使用git安装$ git clone https://github.com/pyenv/pyenv.git ~/.pyenv# 使用Homebrew on Mac OS X 安装$ brew update$ brew install pyenv 没有Homebrew请安装并更新 123456# 配置pyenv的环境，$ echo 'export PYENV_ROOT=\"$HOME/.pyenv\"' &gt;&gt; ~/.bash_profile$ echo 'export PATH=\"$PYENV_ROOT/bin:$PATH\"' &gt;&gt; ~/.bash_profile$ echo -e 'if command -v pyenv 1&gt;/dev/null 2&gt;&amp;1; then\\n eval \"$(pyenv init -)\"\\nfi' &gt;&gt; ~/.bash_profile$ echo -e 'if command -v pyenv 1&gt;/dev/null 2&gt;&amp;1; then\\n eval \"$(pyenv init -)\"\\nfi' &gt;&gt; ~/.bash_profile$ exec \"$SHELL\" 这里的 shell 配置文件（~/.bash_profile）依不同 Linux 而需作修改，如果使用 Zsh 则需要相应的配置 ~/.zshrc 详情见官方doc 用pyenv安装python 1$ pyenv install 3.6.3 pyenv的常用指令 s 更多关于pyenv的使用大家可以参考这篇文章使用 pyenv 管理 Python 版本 查看当前python版本和路径123pyenv versions system* 3.6.3 (set by /Users/baron/.pyenv/version) TensorfFlow 安装 最简单的办法是从官网下载TensorFlow直接安装 当然我们也可以追求性能用源码安装，这里是官方文档 这里介绍CPU版本的安装，GPU版本还需要CUDA和Xcode的环境，这里有关于GPU版本安装的解释 123456789101112131415161718192021222324252627282930313233# 安装 bazelbrew update &amp;&amp; brew install bazel# 安装 python dependencies分别是six numpy wheel# python 2.x pip用以下指令sudo -H pip install six numpy wheel # python 3.x pip3 用以下指令sudo -H pip3 install six numpy wheel # 下载源码git clone https://github.com/tensorflow/tensorflow# 如果使用pyenv之后 建议clone在pyenv的python子文件夹下 # cd 到路径，以下是我的tensflow的路径cd /Users/baron/.pyenv/versions/3.6.3/lib/python3.6/site-packages/tensorflow# 配置编译文件，基本默认选项，建议仔细看下，官方doc有解释，路径一定要注意，tensflow在那个pyrthon下，写哪个python路径# 因为需要下载一些文件，需要开翻墙./configure# 编译没有 GPU 支持版本，很漫长，编译了将近一个小时bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package# 打包到/tmp/tensorflow_pkg下bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg# 查看包名ls -alh /tmp/tensorflow_pkg# 用pip或pip3安装，后面的包名替换成泥自己编译后的pip3 install /tmp/tensorflow_pkg/tensorflow-1.0.0-cp36-cp36m-macosx_10_11_x86_64.whl 在安装报错的时候，尝试加上sudo，若还是不行使用sudo -H，我就因为这个问题耽误好久。注意所有路径问题，编译时显示路径不对，请cd或者更改到你TensorFlow的实际路径 直接安装他人编译好的版本可以在这里下载别人已经编译好的.whl文件来安装或者更新，注意自己的python版本和TensorFlow版本以及系统 检测和更新最后进入IDE，python shell或者terminal 用pyenv选择你安装了tensorflow的python版本 12345678workon mlpython# 进入 python repl 环境&gt;&gt;&gt; import tensorflow as tf&gt;&gt;&gt; hello = tf.constant('Hello, TensorFlow!')&gt;&gt;&gt; sess = tf.Session()&gt;&gt;&gt; print(sess.run(hello))b'Hello, TensorFlow!' 更新对于有强迫症的小伙伴（譬如我更新是必不可少的^_^ 12345678# 更新brew安装过的一切brew update# 查看pip安装过的所有包pip3 list --format=columns# 查看pip安装过的且需要更新的包pip3 list --outdated --format=columns# 一个个输入包名更新就好了sudo -H pip3 install -U 包名 Reference Installing TensorFlow from Sources 源码安装 TensorFlow for Mac OS X","tags":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://www.barondu.com/tags/Machine-Learning/"},{"name":"TensorFlow","slug":"TensorFlow","permalink":"http://www.barondu.com/tags/TensorFlow/"},{"name":"pyenv","slug":"pyenv","permalink":"http://www.barondu.com/tags/pyenv/"}]},{"title":"拓展 N和NP问题","date":"2017-02-06T11:43:27.000Z","path":"2017/02/06/N和NP问题/","text":"N和NP问题 “P” refers to the class of problems that can be solved in polynomial time“NP” refers to problems that can be solved in non- deterministic polynomial time P是能在多项式时间内解决的问题， NP是能在多项式时间验证答案正确与否的问题。 用大白话讲大概就是这样。P是否等于NP实质上就是在问，如果对于一个问题我能在多项式时间内验证其答案的正确性，那么我是否能在多项式时间内解决它？这个表述不太严谨，但通俗来讲就是如此。(2014, Wang) 什么是 polynomial time？ 多项式级的复杂度：O(1),O(log(n)),O(n^a)等，因为它的规模n出现在底数的位置； 非多项式级的复杂度：O(a^n)和O(n!)型复杂度，其复杂度计算机往往不能承受。","tags":[{"name":"G52LAC","slug":"G52LAC","permalink":"http://www.barondu.com/tags/G52LAC/"}]},{"title":"笔记 OSC_Concurrency2","date":"2017-01-09T17:33:27.000Z","path":"2017/01/09/Concurrency2/","text":"Concurrency 2 Overview Software approaches: Peterson’s solution Hardware approaches: Disabling interrupts: test_and_set() compare_and_swap() Higher level approaches include mutexes and semaphoresPeterson’s Solution Peterson’s solution is a software based solution which worked well for older machines Two shared variables are used: turn: indicates which process is next to enter its critical section boolean flag[2]: indicates that a process is ready to enter its critical section It is restricted[限制] to two processes that execute in strict alternation[严格的交替]1234567891011do &#123; flag[j] = true; // j wants to enter critical section turn = i; // allow i to access first while (flag[i] &amp;&amp; turn == i); // whilst i wants to access critical section // and its i’s turn, apply busy waiting // CRITICAL SECTION flag[j] = false; // remainder section&#125; while (...); Peterson’s solution satisfies all requirements for mutual exclusion Mutual exclusion requirement: the variable turn can have at most one value at a time while(flag[i] &amp;&amp; turn == i)or while(flag[j] &amp;&amp; turn == j) is true and at most one process can enter its critical section (mutual exclusion) Disabling Interrupts Disable interrupts whilst executing a critical section and prevent interruption (i.e., interrupts from timers, I/O devices, etc.) Think of the counter++ example = counter;12register = register + 1counter = register; Disabling interrupts “may” be appropriate on a single CPU machine This is inefficient on modern multi-core/multi processor machines Disabling interrupts on all cores/CPUs takes time and causes delays CPU capacity[能力] is lost on other cores Atomic Instructions Implement test_and_set() and swap_and_compare() instructions as a set of atomic (UN-interruptible) instructions Reading and setting the variable(s) is done as one “complete” set of instructions If test_and_set() or compare_and_swap() are called simultaneously, they will be executed sequentially They are used in in combination with global lock variables, assumed to be true if the lock is in use test_and_set() Test and set must be atomic/UN-interruptable1234567891011121314151617// Test and set methodboolean test_and_set(boolean * lock) &#123; boolean rv = *lock; *lock = true; return rv;&#125;// Example of using test and set methoddo &#123; // WHILE the lock is in use, apply busy waiting while (test_and_set(&amp;lock)); // Lock was false, now true // CRITICAL SECTION ... lock = false; ... // remainder section&#125; while (...) compare_and_swap()1234567891011121314151617// Compare and swap methodint compare_and_swap(int *lock, int expected, int new_value) &#123; int temp = *lock; if(*lock == expected) *lock = new_value; return temp;&#125;// Example using compare and swap methoddo &#123; // While the lock is in use (i.e. == 1), apply busy waiting while (compare_and_swap(&amp;lock, 0, 1) != 0); // Lock was false, now true // CRITICAL SECTION ... lock = 0; ... // remainder section&#125; while (...); Disadvantages: test_and_set()and compare_and_swap() are hardware instructions and (usually) not directly accessible to the user Busy waiting is used Starvation is possible Deadlock is possible The OS uses the hardware instructions to implement higher level mechanisms/instructions for mutual exclusion, i.e. mutexes and semaphores ##Summary Peterson’s solution (software) Hardware instructions: interrupt disabling, (test_and_set, compare_and_swap)","tags":[{"name":"OSC","slug":"OSC","permalink":"http://www.barondu.com/tags/OSC/"},{"name":"concurrency","slug":"concurrency","permalink":"http://www.barondu.com/tags/concurrency/"}]},{"title":"笔记 OSC_Concurrency1","date":"2017-01-09T14:09:27.000Z","path":"2017/01/09/Concurrency1/","text":"Concurrency 1 Overview Examples of concurrency issues (e.g. counter++) Root causes of concurrency issues Critical sections and mutual exclusion Requirements and approaches for mutual exclusion Concurrency Threads and processes execute concurrently or in parallel and can share resources Multiprogramming/multiprocessing improves system utilisation A process/thread can be interrupted at any point in time (I/O, timer) The process “state” is saved in the process control block The outcome of programs may become unpredictable[不可预知的] Sharing data can lead to inconsistencies[矛盾] I.e., the outcome of execution may depend on the order win which instructions are carried out Incrementing a counter counter++ consists of three separate actions: 1 read the value of counter and store it in a register 2 add one to the value in the register 3 store the value of the register in counter The above actions are NOT “atomic”, e.g. they can be interrupted by the timer (⇒ context switch) Bounded Buffers Consider a bounded buffer in which N items can be stored A counter is maintained to count the number of items currently in the buffer Incremented when an item is added Decremented when an item is removed Similar concurrency problems as with the calculation of sums happen in the bounded buffer (producer/consumer) problem Race Conditions A race condition occurs when multiple threads/processes access shared data and the result is dependent on the order in which the instructions are interleaved Concurrency within the OSData Structures Kernels are preemptive these days (⇔ non-preemptive) Multiple processes are running in the kernel I.e. kernel processes can be interrupted at any point The kernel maintains data structures, e.g. process tables, memory structures, open file lists, etc. These data structures are accessed concurrently/in parallel These can be subject to concurrency issues Resources Processes share resources, including memory, files, processor time, printers, I/O devices, etc. The operating system must: Allocate and deallocate these resources safely (i.e. avoid interference, deadlocks and starvation) Make sure that interactions within the OS do not result in race conditions The operating system must provide locking mechanisms to implement/support mutual exclusion (and prevent starvation and deadlocks) Critical Sections[临界段], Mutual Exclusion[互斥] A critical section is a set of instructions in which shared variables are changed Mutual exclusion must be enforced for critical sections Only one process at a time should be in the critical section (mutual exclusion) Processes have to get “permission” before entering their critical section123456789do&#123; ... // ENTRY to critical section critical section, e.g.counter++; // EXIT critical section remaining code ...&#125; while (...); Any solution to the critical section problem must satisfy the following requirements: Mutual exclusion: only one process can be in its critical section at any one point in time Progress: any process must be able to enter its critical section at some point in time Fairness/bounded waiting: processes cannot be made to wait indefinitely These requirements have to be satisfied, independent of the order in which sequences are executed Enforcing Mutual Exclusion Approaches for mutual exclusion can be: Software based: Peterson’s solution Hardware based: test_and_set(), swap_and_compare() Based on: Mutexes Semaphores Monitors (software construct within the programming languages) In addition to mutual exclusion, deadlocks have to be prevented (next week’s subject) Summary Examples of concurrency issues (e.g. counter++) Root causes of concurrency issues Critical sections and mutual exclusion Requirements and approaches for mutual exclusion","tags":[{"name":"OSC","slug":"OSC","permalink":"http://www.barondu.com/tags/OSC/"},{"name":"concurrency","slug":"concurrency","permalink":"http://www.barondu.com/tags/concurrency/"}]},{"title":"笔记 OSC_Processes4","date":"2017-01-09T14:05:27.000Z","path":"2017/01/09/Processes4/","text":"Processes 4 Overview Multi-level feedback queues Scheduling in Window 7 + illustration Scheduling in Linux (implementation in labs) Scheduling related processes/threads Multi-level Feedback Queues Different scheduling algorithms can be used for the individual queues (e.g., round robin, SJF, FCFS) Feedback queues allow priorities to change dynamically[动态的], i.e., jobs can move between queues: Move to lower priority queue if too much CPU time is used (prioritise I/O and interactive processes) Move to higher priority queue to prevent starvation and avoid inversion[反转] of control Defining characteristics of feedback queues include: The number of queues The scheduling algorithms used for the individual queues Migration policy[迁移政策] between queues Initial access to the queuesFeedback queues are highly configurable[可配置] and offer significant flexibility[灵活性，适应性] Windows 7 An interactive system[交互系统] using a preemptive scheduler with dynamic priority levels Two priority classes with 16 different priority levels exist “Real time” processes/threads have a fixed priority level “Variable” processes/threads can have their priorities boosted temporarily A round robin algorithm is used within the queues Priorities are based on the process base priority (between 0-15) and thread base priority (±2 relative to the process priority) A thread’s priority dynamically changes during execution between its base priority and the maximum priority within its class Interactive I/O bound processes (e.g. keyboard) receive a larger boost Boosting priorities prevents priority inversion Scheduling in LinuxThe Completely Fair Scheduler Linux distinguishes[区分] between two types of tasks for scheduling: Real time tasks (to be POSIX compliant), divided into: Real time FIFO tasks Real time Round Robin tasks Time sharing tasks using a preemptive approach (similar to variable in Windows) The most recent scheduling algorithm in Linux for time sharing tasks is the “completely fair scheduler” Real-Time Tasks Real time FIFO tasks have the highest priority and are scheduled using a FCFS approach, using preemption if a higher priority job shows up Real time round robin tasks are preemptable by clock interrupts and have a time slice associated with them Both approaches cannot guarantee hard deadlines Time Sharing Tasks The CFS divides the CPU time between all processes If all N processes have the same priority: They will be allocated a “time slice” equal to 1/N times the available CPU time I.e., if N equals 5, every process will receive 20% of the processor’s time The length of the time slice and the “available CPU time” are based on the targeted latency[延迟] (⇒ every process should run at least once during this interval) If N is very large, the context switch time will be dominant, hence a lower bound on the “time slice” is imposed by the minimum granularity[粒度] A process’s time slice can be no less than the minimum granularity (response time will deteriorate[恶化]) A weighting scheme is used to take different priorities into account If process have different priorities: Every process i is allocated a weight Wi that reflects its priority The tasks with the lowest amount of “used CPU time” are selected first Shared Queues A single or multi-level queue shared between all CPUs Advantage: automatic load balancingDisadvantages: Contention[竞争] for the queues (locking is needed) “All CPUs are equal, but some are more equal than others” : does not account for processor affinity[紧密度]: Cache becomes invalid when moving to a different CPU Translation look aside buffers (TLBs - part of the MMU) become invalid Windows will allocate the highest priority threads to the individual CPUs/cores Private Queues Each process/thread is assigned to a queue private to an individual CPU Advantages: CPU affinity is automatically satisfied Contention for shared queue is minimised Disadvantages: less load balancing Push and pull migration between CPUs is possible Related vs. Unrelated ThreadsRelated: multiple threads that communicate with one another and ideally run together (e.g. search algorithm) Unrelated: e.g. processes threads that are independent, possibly started by different users running different programs Related Threads The aim is to get threads running, as much as possible, at the same time across multiple CPUs Approaches include: Space sharing Gang scheduling Gang scheduling Time slices are synchronised[同步的] and the scheduler groups threads together to run simultaneously (as much as possible) A preemptive algorithm Blocking threads result in idle CPUs Summary Scheduling on Windows and Linux Multi-processor/core scheduling is “a bit different” (load balancing, processor affinity, etc.) Related and unrelated threads Shared or private queues Space scheduling or gang scheduling","tags":[{"name":"OSC","slug":"OSC","permalink":"http://www.barondu.com/tags/OSC/"},{"name":"processes","slug":"processes","permalink":"http://www.barondu.com/tags/processes/"}]},{"title":"笔记 OSC_Processes3","date":"2017-01-08T23:27:27.000Z","path":"2017/01/08/Processes3/","text":"Processes 3 Overview1 Threads vs. processes2 Different thread implementations3 POSIX Threads (PThreads) ThreadsThreads from an OS Perspective[观点] A process consists of two fundamental units Resources: all related resources are grouped together A logical address space containing the process image (program, data, heap, stack) Files, I/O devices, I/O channels, . . . Execution trace[执行追踪], i.e., an entity that gets executed A process can share its resources between multiple execution traces, i.e., multiple threads running in the same resource environment Every thread has its own execution context (e.g. program counter, stack, registers) All threads have access to the process’ shared resources E.g. files, one thread opens a file, all threads of the same process can access the file Global variables, memory, etc. (⇒ synchronisation!) Some CPUs (hyperthreaded ones) have direct hardware support for multi-threading Similar to processes, threads have: States and transitions (new, running, blocked, ready, terminated) A thread control blockThreads create/terminate/switch with less overhead (address space remains the same for threads of the same process) Inter-thread communication is easier/faster than inter-process communication (threads share memory by default) No protection boundaries[边界] are required in the address space (threads are cooperating, belong to the same user, and have a common goal) Synchronisation has to be considered carefully! Why Use Threads Multiple related activities apply to the same resources, these resources should be accessible/shared Processes will often contain multiple blocking tasks I/O operations (thread blocks, interrupt marks completion) Memory access: pages faults are result in blocking Such activities should be carried out in parallel/concurrently Application examples: webservers, make program, spreadsheets, word processors, processing large data volumes OS Implementations of Threads User threads Kernel threads Hybrid[混合] implementations User ThreadsMany-to-One Thread management (creating, destroying, scheduling, thread control block manipulation[处理]) is carried out in user space with the help of a user library The process maintains a thread table managed by the runtime system without the kernel’s knowledge Similar to process table Used for thread switching Tracks thread related information Advantages: Threads are in user space (i.e., no mode switches required) Full control over the thread scheduler OS independent[独立不受约束] (threads can run on OS that do not support them) Disadvantages: Blocking system calls suspend[延缓] the entire process (user threads are mapped onto a single process, managed by the kernel) No true parallelism (a process is scheduled on a single CPU) Clock interrupts are non-existent (i.e. user threads are non-preemptive) Page faults[错误] result in blocking the process Kernel ThreadsOne-to-One The kernel manages the threads, user application accesses threading facilities[工具] through API and system calls Thread table is in the kernel, containing thread control blocks (subset of process control blocks) If a thread blocks, the kernel chooses thread from same or different process (↔ user threads) Windows and Linux apply this approach Advantages: True parallelism can be achieved No run-time system needed Disadvantage: Frequent mode switches take place, resulting in lower performance Frequent mode switches take place, resulting in lower performance Performance Hybrid ImplementationsMany-to-Many User threads are multiplexed onto kernel threads Kernel sees and schedules the kernel threads (a limited number) User application sees user threads and creates/schedules these (an “unrestricted” number) Comparison Thread Management Thread libraries provide an API/interface for managing threads (e.g. creating, running, destroying, synchronising, etc.) Thread libraries can be implemented: Entirely in user space (i.e. user threads) Based on system calls Examples of thread APIs include POSIX’s PThreads, Windows Threads, and Java Threads The PThread specification can be implemented as user or kernel threads POSIX threads are a specification that “anyone” can implement, i.e., it defines a set of APIs (function calls, over 60 of them) and what they do Summary Threads vs. processes Thread implementations (user, kernel and hybrid) PThreads","tags":[{"name":"OSC","slug":"OSC","permalink":"http://www.barondu.com/tags/OSC/"},{"name":"processes","slug":"processes","permalink":"http://www.barondu.com/tags/processes/"}]},{"title":"笔记 OSC_Processes2","date":"2017-01-08T23:26:14.000Z","path":"2017/01/08/Processes2/","text":"Processes 2 Overview Introduction to process scheduling Types of process schedulers Evaluation criteria for scheduling algorithms Typical process scheduling algorithms Process SchedulingContext The OS is responsible for managing and scheduling processes Decide when to admit processes to the system (new → ready) Decide which process to run next (ready → run) Decide when and which processes to interrupt (running → ready) It relies on the scheduler (dispatcher) to decide which process to run next, which uses a scheduling algorithm to do so The type of algorithm used by the scheduler is influenced by the type of operating system (e.g., real time vs. batch) Classification by Time Horizon Long term: applies to new processes and controls the degree of multiprogramming by deciding which processes to admit to the system A good mix of CPU and I/O bound processes is favourable to keep all resources as busy as possible Usually absent in popular modern OS Medium term: controls swapping and the degree of multi-programming Short term: decide which process to run next Usually called in response to clock interrupts, I/O interrupts, or blocking system calls Invoked[调用] very frequently, hence must be fast Manages the ready queue Classification by Approach Non-preemptive: processes are only interrupted voluntarily[自愿的] (e.g., I/O operation or “nice” system call – yield()) Preemptive[优先的]: processes can be interrupted forcefully or voluntarily This requires context switches which generate overhead, too many of them should be avoidedPrevents processes from monopolising[垄断的] the CPU Most popular modern operating systems are preemptive Performance Assessment[性能评估]User oriented[导向]criteria: Response time: minimise the time between creating the job and its first execution Turnaround time: minimise the time between creating the job and finishing it Predictability[可调度性]: minimise the variance[差异，方差] in processing times System oriented criteria: Throughput[吞吐量]: maximise the number of jobs processed per hour Fairness[公平性]: Are processing power/waiting time equally distributed? Are some processes kept waiting excessively long (starvation) Evaluation criteria can be conflicting, i.e., reducing the response time may increase context switches and may worsen the throughput and increase the turn around time Scheduling AlgorithmsAlgorithms considered: First Come First Served (FCFS)/ First In First Out (FIFO) Shortest job first Round Robin Priority queues Performance measures used: Average response time Average turnaround time First Come First Served Concept: a non-preemtive algorithm that operates as a strict[严格的] queueing mechanism[机制] and schedules the processes in the same order that they were added to the queue Advantages: positional fairness and easy to implement Disadvantages: good for long processes over short ones Could compromise[危害] resource utilisation, i.e., CPU vs. I/O devices Shortest Job First Concept: A non-preemtive algorithm that starts processes in order of ascending[递增] processing time using a provided/known estimate of the processing Advantages: always result in the good turn around time Disadvantages: Starvation[饿死] might occur Fairness and predictability are compromised Processing times have to be known beforehand Round Robin Concept: a preemptive version of FCFS that forces context switches at periodic[周期性] intervals[间隔] or time slices Processes run in the order that they were added to the queue Processes are forcefully interrupted by the timerAdvantages: Improved response time Effective for general purpose time sharing systemsDisadvantages: Increased context switching and thus overhead Favours CPU bound processes (which usually run long) over I/O processes (which do not run long) Can reduce to FCFS The length of the time slice must be carefully considered! a low response time is achieved with a small time slice (e.g. 1ms) ⇒ low throughput a high throughput is achieved with a large time slice (e.g. 1000ms) ⇒ high response time If a time slice is only used partially, the next process starts immediately Priority Queues Concept: A preemptive algorithm that schedules processes by priority (high → low) The process priority is saved in the process control block Advantages: can prioritise[优先] I/O bound jobs Disadvantages: low priority processes may suffer from starvation (with static priorities) ##Summary Types of schedulers: preemptive/non-preemptive, long/medium/short term) Performance evaluation criteria Scheduling algorithms: FCFS, SJF, Round Robin, Priority Queues","tags":[{"name":"OSC","slug":"OSC","permalink":"http://www.barondu.com/tags/OSC/"},{"name":"processes","slug":"processes","permalink":"http://www.barondu.com/tags/processes/"}]},{"title":"笔记 OSC_Processes1","date":"2017-01-06T11:42:14.000Z","path":"2017/01/06/Processes1/","text":"Processes 1 Overview Introduction to processes and their implementation Process states and state transitions System calls for process management Processes and Implementation Definition: “a process is a running instance of a program”进程是程序的运行实例 A process is registered with the OS using its “control structures”: i.e. an entry in the OS’s process table to a process control blocks (PCB) The process control block contains all information necessary to manage the process and is necessary for context switching in multi-programmed systems A process’ memory image contains: The program code (could be shared between multiple processes running the same code) A data segment, stack and heap Every process has its own logical address space, in which the stack and heap are placed at opposite[相反的] sides to allow them to grow Process States and TransitionsSates: A new process has just been created (has a PCB) and is waiting to be admitted (it may not yet be in memory) A ready process is waiting for CPU to become available (e.g. unblocked or timer interrupt) A running process “owns” the CPU A blocked process cannot continue, e.g. is waiting for I/O A terminated process is no longer executable (the data structures - PCB - may be temporarily preserved) A suspended[废除的] process is swapped out[换出] (not discussed further) Transitions： New -&gt; ready: admit the process and commit to execution Running -&gt; blocked: e.g. process is waiting for input or carried out asystem call Ready -&gt; running: the process is selected by the process scheduler Blocked -&gt; ready: event happens, e.g. I/O operation has finished . Running -&gt; ready: the process is preempted, e.g., by a timer interrupt orby pause Running -&gt;strong text exit: process has finished, e.g. program ended or exceptionencountered The interrupts/traps/system calls lie on the basis of the transitions Context SwitchingMulti-programming Modern computers are multi-programming systems Assuming a single processor system, the instructions of individual processes are executed sequentially Multi-programming goes back to the “MULTICS” age Multi-programming is achieved by alternating[交替]processes and context switching True parallelism requires multiple processors并不是真正的multi-programming When a context switch takes place, the system saves the state of the old process and loads the state of the new process (creates overhead) Saved -&gt; the process control block is updated (Re-)started -&gt; the process control block read A trade-off[权衡] exists between the length of the time-slice and the context switch time Short time slices result in good response times but low effective “utilisation”[使用] e.g.: 99*(1+1)=198ms Long time slices result in poor response times but better effective “utilisation” e.g.: 99 * (100 + 1) = 9999ms A process control block contains three types of attributes: Process identification (PID, UID, Parent PID) Process control information (process state, scheduling information, etc.) Process state information (user registers, program counter, stack pointer, program status word, memory management information, files, etc.) Process control blocks are kernel data structures, i.e. they are protected and only accessible in kernel mode! Allowing user applications to access them directly could compromise[威胁] their integrity[完整性] The operating system manages them on the user’s behalf through system calls (e.g. to set process priority) Tables and Control Blocks An operating system maintains information about the status of “resources” in tables Process tables (process control blocks) Memory tables (memory allocation, memory protection, virtual memory) I/O tables (availability, status, transfer information) File tables (location, status) The process table holds a process control block for each process, allocated upon process creation Tables are maintained by the kernel and are usually cross referencedSwitching Processes Save process state (program counter, registers) Update PCB (running -&gt; ready/blocked) Move PCB to appropriate queue (ready/blocked) Run scheduler, select new process Update to running state in the new PCB Update memory management unit (MMU) Restore process System Calls System calls are necessary to notify the OS that the process has terminated Resources must be de-allocated Output must be flushed Process admin may have to be carried out A system calls for process termination: UNIX/Linux: exit(), kill() Windows: TerminateProcess() Summary Definition of a process and their implementation in operating systems States, state transitions of processes Kernel structures for processes and process management System calls for process management","tags":[{"name":"OSC","slug":"OSC","permalink":"http://www.barondu.com/tags/OSC/"},{"name":"processes","slug":"processes","permalink":"http://www.barondu.com/tags/processes/"}]},{"title":"笔记 OSC_Introduction2","date":"2017-01-03T23:50:14.000Z","path":"2017/01/03/Introduction2/","text":"Introduction 2 Overview CPU design Address spaces, interruts OS structures/implementation CPU design A CPU basic cycle consist of fetch[取], decode, execute Every CPU has his own instruction set CPU has a set of registers Registers are used to store data and for special functions (e.g. program counter, program status word – mode bit) The compiler/programmer decides what to keep in the registers Context switching[上下文切换] must save and restore the CPU’s internal state, including its registers Memory Management Unit (MMU) Memory adsresses from 0 to MAX Variables are mnemonic[帮助记忆的] names for memory addresses You don’t know where the process will run in physical memory at compile time Multiple processes run on modern machines The compiler assumes that it will start running at 0 (logical address space) An offset[补偿] is added at runtime by the MMU (physical address space) physical address = logical address + offset Modern computer use a logical and physical memory addresses: Every process has a logical address space – [0,MAX64] (theoretically理论上) The machine has a physical address space – [0, MAX ] (MAX determined by the amount of physical memory) Address translation takes place in MMU physical = f (logical ) A context switch between processes invalidates[使无效] the MMU (as well as registers, cache, … ) Timer interrupts Interrupts temporarily pause a process’s normal operation Different types of interrupts: Timer interrupts by CPU clock I/O interrupts for I/O completion or error codes Software generated, e.g. errors and exceptions Timer generates an interrupt CPU finishes current instruction and tests for interrupt Transfer to interrupt service routine Hardware saves current process state (PSW, program counter) Set program counter to interrupt service routine Save registers and other state information Carry out[执行] interrupt service routine (scheduler) Restore next process to run Moore’s “law” Moore’s “law”: “The number of transistors on an integrated circuit (chip) doubles roughly every two years” Closely linked, but not necessarily related to performance The “power wall” slows performance improvements of single core/single processor systems A few cores for multiple “programs” is easy to justify How to use massively[大规模的] parallel computers/CPUs/many core machines Can we extract parallelism automatically, can we implement parallelism at the lowest level (similar to multiprogramming) Multi-core, hyperthreaded processors Modern CPUs contain multiple cores and are often hyper-threaded Evolution in hardware has implications on operating system design XP did not support multi processor architectures Process scheduling needs to account for load balancing and CPU affinity[亲和性] Cache coherency[缓存一致性] becomes important Memory Memory hierarchies[层级] used to balance cost and performance Fast and expensive memory is used for caching Slow and inexpensive memory is used for long term storage Memory includes, registers, L1/L2 cache, main/core memory, disk, etc. L2 Cache can be shared or dedicated[专注的] to individual cores Cache management is mainly done by hardware The CPU can only access main memory directly (i.e. files have to be brought into memory first) I/O Devices Device driver interacts[交互] with the controller, controller interacts with the device (e.g., disk controller) The operating system/device driver typically communicates with the controller through registers I/O can take place through: Busy waiting Interrupt based Direct memory access (using DMA chip) Operating System Structure Systems contain a lot of functionality Operating Systems are structured by Micro kernels[微内核] and Monolithic[单内核] Micro Kernels All non-essential functionality is extracted[取出] from the kernel Communication, memory management and CPU scheduling are likely to be included in the kernel The file system, GUI, device drivers are likely to be user processes除了保留基本功能，其他功能移出到user mode Micro kernels are more easy to extend, more portable[便携], and usually more reliable Frequent system calls and kernel traps[陷阱] cause significant overhead[开销] (mode switches) Some Unix version, Mac OS X, Minix, and early versions of Windows (NT4.0) were (partially) micro kernels Monolithic Systems All procedures are linked together into one single executable running in kernel mode Monolithic kernels are difficult to maintain Current versions of Windows, Linux are implemented as monolithic kernels操作系统高度紧密，移植性不佳。但是若设计完善，效率高 Summary Operating Systems are closely linked to computer architecture Address translation and interrupts OS structures","tags":[{"name":"OSC","slug":"OSC","permalink":"http://www.barondu.com/tags/OSC/"},{"name":"Introduction","slug":"Introduction","permalink":"http://www.barondu.com/tags/Introduction/"}]},{"title":"笔记 OSC_Introduction1","date":"2017-01-01T15:06:04.000Z","path":"2017/01/01/Introduction1/","text":"Introduction 1 Overview “Defining“ operating systems What is multi-programming Kernel-user mode Defining Operating Systems In the early days, programmers had to deal directly with hardware Real computer hardware is urgly Hardware is extremely difficult to program An operating system is a layer[层] of indirection[间接] on top of the hardware: It provide abstractions for application programs it provide a cleaner and easier interface to the hardware Multi-programming Morden OS use multi-programming to improve user experience and maximise the use of resource Disk is slow. CPU is faster than disk. Without multi-programming, CPU time is waste while wating for I/O requests. Multi-programming has important consequences[结果] for operating system design The operating system must allocate[分配]/share resources (CPU, memory, I/O devices) fairly and safely between competing processes: In time, e.g. CPUs and printers In space, e.g., memory and disks The execution of multiple programs (processes) needs to be interleaved[交错] with one another. This requires: This requires context switches and process scheduling ⇒ mutual exclusion[相互排斥], deadlock avoidance, protection, . . . Kernel-user mode Modern operating systems have multiple modes: The operating system runs in kernel mode and has access to all instructions Applications run in user mode and have access to a subset of instructions Transitions from user mode to kernel mode happen in a controlled manner (interrupts, exceptions, system calls) and are mirrored in hardware Summary Some properties: Sits directly on top of the hardware Has access to the full capabilities of the hardware Provides abstractions for the user/programmer Makes sure that everything is organised and runs in order Improve the hardware interface","tags":[{"name":"OSC","slug":"OSC","permalink":"http://www.barondu.com/tags/OSC/"},{"name":"Introduction","slug":"Introduction","permalink":"http://www.barondu.com/tags/Introduction/"}]}]